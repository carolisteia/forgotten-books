{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "technical-password",
   "metadata": {},
   "source": [
    "# The Forgotten Books:  Unseen Species Models and the Survival of Medieval Literature\n",
    "## Supporting code \n",
    "\n",
    "The code in the present notebook relies on the `copia` software package (for Python 3.6+), which is available from [Github](https://github.com/mikekestemont/copia) and documented [here](https://copia.readthedocs.io/en/latest/). A recent version can be installed from PyPI (`>>> pip install copia`). In the cell below, we import the other modules on which the software depends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(543251) # control random seed\n",
    "\n",
    "import copia.utils as u\n",
    "from copia.plot import accumulation_curve\n",
    "from copia.richness import species_accumulation\n",
    "from copia.utils import survival_ratio\n",
    "from copia.plot import multi_kde\n",
    "from copia.plot import survival_errorbar\n",
    "from copia.hill import hill_numbers\n",
    "from copia.utils import evenness\n",
    "from copia.plot import evenness_plot\n",
    "from copia.plot import density\n",
    "from copia.plot import hill_plot\n",
    "from copia.richness import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-march",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-restriction",
   "metadata": {},
   "source": [
    "This repository ships with all datasets used in the study, which can be found as spreadsheets under `datasets/master`. We load the individual assemblages and convert them to `pandas` DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "lits = {}\n",
    "for fn in sorted(glob.glob('../datasets/master/*.xlsx')):\n",
    "    if 'anglo-norman' in fn:\n",
    "        continue\n",
    "    df = pd.read_excel(fn).dropna(subset = [\"title\"])\n",
    "    lang = os.path.basename(fn).replace('.xlsx', '').lower()\n",
    "    lits[lang] = df[['title', 'signature', 'repository']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-extraction",
   "metadata": {},
   "source": [
    "Next, we extract a high-number of high-level statistics from these datasets ($f_1$, $f_2$, $n$, and $S$, as well as the number of distinct repositories), which we cast to what is known as \"abundance data\" in ecology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "for lit, df in lits.items():\n",
    "    abundance = u.to_abundance(df['title'])\n",
    "    s = u.basic_stats(abundance)\n",
    "    d = {'language': lit}\n",
    "    for k in ('f1', 'f2', 'S', 'n'):\n",
    "        d[k] = s[k]\n",
    "    d['repo'] = len(set(df['repository']))\n",
    "    stats.append(d)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-discussion",
   "metadata": {},
   "source": [
    "We add similar statistics for the union of the datasets, but do not include the number of repositories (because these have not been disambiguated across the assemblages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(stats)\n",
    "stats_df['language'] = stats_df['language'].str.lower()\n",
    "stats_df.loc[len(stats_df)] = ['all'] + list(stats_df[['f1', 'f2', 'S', 'n']].sum()) + [None]\n",
    "stats_df = stats_df.set_index('language')\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-afghanistan",
   "metadata": {},
   "source": [
    "## Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-adaptation",
   "metadata": {},
   "source": [
    "We start by analyzing the union of the six datasets. We explicitly add a language tag to each work's title, to avoid naming conflicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for lang, df in lits.items():\n",
    "    df['title'] = [t+'_'+lang for t in df['title']]\n",
    "    dfs.append(df)\n",
    "    \n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-banana",
   "metadata": {},
   "source": [
    "We convert this information to abundance data, using a utility function from `copia`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance = u.to_abundance(df_all['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-philippines",
   "metadata": {},
   "source": [
    "We'll store all resulting assets to an `outputs` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../outputs')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-discussion",
   "metadata": {},
   "source": [
    "First, we obtain point estimates for the survival of the numbers of works (\"Chao1\") and documents (\"minsample\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original # works:', diversity(abundance, method='chao1'))\n",
    "print('original # documents:', diversity(abundance, method='minsample'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-organizer",
   "metadata": {},
   "source": [
    "We continue with plotting density curves that show the bootstrap estimates (and associated quantiles) for the diversity estimates as survival ratios. Note that `survival_ratio()` converts the initial estimate to a survival rate, i.e. by taking the ratio of the estimates over the observed $S$ and $n$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsurvival_all = survival_ratio(abundance, method='chao1', n_iter=10000)\n",
    "density(wsurvival_all, xlim=(0.4, 1));\n",
    "plt.savefig('../outputs/dens_works.pdf')\n",
    "\n",
    "dsurvival_all = survival_ratio(abundance, method='minsample', n_iter=10000)\n",
    "density(dsurvival_all, xlim=(0, 0.15))\n",
    "plt.savefig('../outputs/dens_docs.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-cardiff",
   "metadata": {},
   "source": [
    "Next, we plot the so-called **species accumulation curve** for the union of the datasets (which will take a while to run). This curve is relevant for specialists of medieval literature, as it gives an indication of the rate at which we might still be discovering new works in the future, by sighting more documents (provided these witnesses have yet not been lost beyond retrieval):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 60000 # this number already takes into account the minsample-estimate\n",
    "accumulation = species_accumulation(abundance, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-portal",
   "metadata": {},
   "source": [
    "To this plot, we will later add a kernel-density estimate that shows the bootstrapped estimates from the `minsample` estimate (on the secondary, horizontal axis). Informally, the resulting blob corresponds to the area where we expect the asymptotic curve from the previous to start saturating. During the `minsample`'s bootstrap procedure initiated in the cell below, `UserWarning`s may sporadically appear in cases where the optimization didn't satisfactorily converge. This is expected behavior.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "minsample_est = diversity(abundance, method='minsample', \n",
    "                          solver='fsolve', CI=True, n_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-inspector",
   "metadata": {},
   "source": [
    "Finally, we plot the Hill number profile for the union of the datasets. We can do this both for the emprically observed data, as well as the bias-corrected reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp, est = hill_numbers(abundance, n_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-prescription",
   "metadata": {},
   "source": [
    "We now combine the statistics calculated above into a single plot, where the species accumulation curve is plotted inside the Hill plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "left, bottom, width, height = [0.44, 0.45, 0.35, 0.35]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "hill_plot(emp, est, add_densities=False, ax=ax)\n",
    "ax2 = fig.add_axes([left, bottom, width, height])\n",
    "ax2.set_facecolor('lightgrey')\n",
    "\n",
    "accumulation_curve(abundance, accumulation, c0='C2', c1='black',\n",
    "                   xlabel='documents', ylabel='works',\n",
    "                   title='species accumulation curve', ax=ax2,\n",
    "                   minsample=minsample_est, xlim=(0, max_steps))\n",
    "\n",
    "plt.savefig('../outputs/all_comb.pdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-nicaragua",
   "metadata": {},
   "source": [
    "## Language-specific estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-legislation",
   "metadata": {},
   "source": [
    "We now turn to the estimates for the individual vernaculars considered. We first convert the available counts data to abundance data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblages = {}\n",
    "for lit, df in lits.items():\n",
    "    abundance = u.to_abundance(df['title'])\n",
    "    assemblages[lit] = abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-rolling",
   "metadata": {},
   "source": [
    "Point estimates for the original diversity of these assemblages are straightforward to obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, assemblage in assemblages.items():\n",
    "    print('category:', category)\n",
    "    print('  - original # works:', diversity(assemblage, method='chao1'))\n",
    "    print('  - original # documents:', diversity(assemblage, method='minsample'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-special",
   "metadata": {},
   "source": [
    "The survival ratios resulting from the bootstrap procedure can be calculated in the following way;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsurvival = {}\n",
    "for category, assemblage in assemblages.items():\n",
    "    wsurvival[category] = survival_ratio(assemblage, method='chao1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-benefit",
   "metadata": {},
   "source": [
    "`copia` offers two auxiliary functions to visualize and compare the (bootstrapped) results across multiple assemblages. First, using colored kernel-density estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = multi_kde(wsurvival)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('Survival ratio (works)')\n",
    "ax.set_ylabel('Bootstrap KDE')\n",
    "ax.set_yticklabels([])\n",
    "plt.savefig('../outputs/survival_works_kde.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-uncle",
   "metadata": {},
   "source": [
    "(Note how two clusters emerge.) Secondly, using error bars corresponding to the confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_errorbar(wsurvival)\n",
    "plt.savefig('../outputs/survival_works_error.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-doubt",
   "metadata": {},
   "source": [
    "The previous cells were for the survival ratios of works; those for documents can be calculated and plotted analogously. Relatively speaking, the results for documents mirror those for the works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsurvival = {}\n",
    "for category, assemblage in assemblages.items():\n",
    "    dsurvival[category] = survival_ratio(assemblage, method='minsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = multi_kde(dsurvival)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlim((0, 0.35))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xlabel('Survival ratio (documents)')\n",
    "plt.savefig('../outputs/survival_docs_kde.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_errorbar(dsurvival)\n",
    "plt.savefig('../outputs/survival_docs_error.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-control",
   "metadata": {},
   "source": [
    "We can now summarize the results for the language-specific estimation into a single overview table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in 'CH1 CH1-lCI CH1-uCI MS MS-lCI MS-uCI'.split():\n",
    "    stats_df[c] = 0.0\n",
    "\n",
    "# for individual languages:\n",
    "for lang in wsurvival:\n",
    "    stats_df.loc[lang, 'CH1'] = wsurvival[lang]['survival']\n",
    "    stats_df.loc[lang, 'CH1-lCI'] = wsurvival[lang]['lci']\n",
    "    stats_df.loc[lang, 'CH1-uCI'] = wsurvival[lang]['uci']\n",
    "\n",
    "for lang in dsurvival:\n",
    "    stats_df.loc[lang, 'MS'] = dsurvival[lang]['survival']\n",
    "    stats_df.loc[lang, 'MS-lCI'] = dsurvival[lang]['lci']\n",
    "    stats_df.loc[lang, 'MS-uCI'] = dsurvival[lang]['uci']\n",
    "    \n",
    "# for union:\n",
    "stats_df.loc['all', 'CH1'] = wsurvival_all['survival']\n",
    "stats_df.loc['all', 'CH1-lCI'] = wsurvival_all['lci']\n",
    "stats_df.loc['all', 'CH1-uCI'] = wsurvival_all['uci']\n",
    "\n",
    "stats_df.loc['all', 'MS'] = dsurvival_all['survival']\n",
    "stats_df.loc['all', 'MS-lCI'] = dsurvival_all['lci']\n",
    "stats_df.loc['all', 'MS-uCI'] = dsurvival_all['uci']\n",
    "\n",
    "stats_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-resource",
   "metadata": {},
   "source": [
    "The cell below dumps the result to a Latex table for inclusion in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../outputs/results.txt', 'w') as f:\n",
    "    f.write(stats_df.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-medicine",
   "metadata": {},
   "source": [
    "### Evenness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-iceland",
   "metadata": {},
   "source": [
    "For plotting the evenness profiles, we first need to calculate the (estimated, reconstructed) Hill number profile for each of the languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "hill_est = {}\n",
    "for lang, assemblage in assemblages.items():\n",
    "    _, est = hill_numbers(assemblage, n_iter=10000)\n",
    "    hill_est[lang] = est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-ethernet",
   "metadata": {},
   "source": [
    "We can compute the (normalized) evenness profiles on the basis of the Hill number profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "evennesses = {l:evenness(hill_est[l]) for l in hill_est}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-philadelphia",
   "metadata": {},
   "source": [
    "Plotting these in a single graph can be done through calling the associated auxiliary function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "evenness_plot(evennesses)\n",
    "plt.savefig('../outputs/evenness.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-tobago",
   "metadata": {},
   "source": [
    "## Anglo-Norman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-absorption",
   "metadata": {},
   "source": [
    "Because the scores for Middle English are so (extremely) low, it is worth investigating the ffect of complementing the English data with abundance data from Anglo-Norman literature. We can load this data, ignored above, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_fn = '../datasets/master/anglo-norman.xlsx'\n",
    "an = pd.read_excel(an_fn).dropna(subset = [\"title\"])\n",
    "an = an[['title', 'signature']]\n",
    "an"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-differential",
   "metadata": {},
   "source": [
    "In the cell below, we repeat some of the basic analyses above for the estimating the works diversity of the combined Middle English and Anglo-Norman data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = {'English': assemblages['english'],\n",
    "        'English with anglo-norman': np.concatenate((assemblages['english'],\n",
    "                                                 u.to_abundance(an['title'])))\n",
    "       }\n",
    "\n",
    "wsurvival = {}\n",
    "for category, assemblage in comp.items():\n",
    "    wsurvival[category] = survival_ratio(assemblage, method='chao1', n_iter=10000)\n",
    "    \n",
    "ax = multi_kde(wsurvival)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('Survival ratio (works)')\n",
    "ax.set_ylabel('Bootstrap KDE')\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "plt.savefig('../outputs/anglonorman.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, res in wsurvival.items():\n",
    "    print(f'{cat}: {round(res[\"survival\"], 3)} [{round(res[\"lci\"], 3)}-{round(res[\"uci\"], 3)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-resolution",
   "metadata": {},
   "source": [
    "## Additional estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-spelling",
   "metadata": {},
   "source": [
    "In the paper, we focus on Chao1, which is an established and robust method in ecology. It is useful to compare the results, however, to a number of additional estimators for the work survival. From `copia`, the following alternatives are available:\n",
    "- the higher-order **Jackknife**: a more general method for bias-correction in statistics\n",
    "- **iChao1**: an variant of Chao1, that also takes into account $f_3$ and $f_4$\n",
    "- the **Egghe & Proot** estimator, using the default setting of `alpha=150`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = []\n",
    "\n",
    "for estimator in ['chao1', 'jackknife', 'ichao1', 'egghe_proot']:\n",
    "    for category, assemblage in assemblages.items():\n",
    "        surv = survival_ratio(assemblage, method=estimator, n_iter=10000)\n",
    "        comp.append([category, estimator, surv['survival'], surv['lci'], surv['uci']])\n",
    "        \n",
    "comp = pd.DataFrame(comp, columns=['tradition', 'estimator', 'survival', 'lci', 'uci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = comp.sort_values(['tradition', 'estimator'])\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../outputs/other.txt', 'w') as f:\n",
    "    f.write(estimates.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-fireplace",
   "metadata": {},
   "source": [
    "We can visualize these results using a bar plot to obtain a better overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.array(list(zip(estimates['lci'], estimates['uci']))).T\n",
    "errors[0] = estimates['survival'] - errors[0]\n",
    "errors[1] -= estimates['survival']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "traditions = tuple(set(estimates['tradition']))\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color'][:len(traditions)]\n",
    "color_dict = dict(zip(traditions, colors))\n",
    "labeled = {t:False for t in color_dict}\n",
    "\n",
    "for idx in range(len(estimates)):\n",
    "    trad = estimates['tradition'].iloc[idx]\n",
    "    meth = estimates['estimator'].iloc[idx]\n",
    "    if not labeled[trad]:\n",
    "        c = color_dict[trad]\n",
    "        labeled[trad] = True\n",
    "        ax.errorbar(idx, estimates['survival'].iloc[idx],\n",
    "            yerr=np.array([errors[:, idx]]).T,\n",
    "            fmt='.', c=color_dict[trad], label=trad,\n",
    "            ms=12)\n",
    "    else:\n",
    "        ax.errorbar(idx, estimates['survival'].iloc[idx],\n",
    "            yerr=np.array([errors[:, idx]]).T,\n",
    "            fmt='.', c=color_dict[trad], ms=12)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Survival ratio (works) for different combinations of estimators and traditions', fontsize=14)\n",
    "ax.set_xticks(np.arange(len(estimates)))\n",
    "ax.set_xticklabels(estimates['estimator'], rotation = 90, fontsize=14);\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/other.pdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-divide",
   "metadata": {},
   "source": [
    "As can be seen, the methods show differences but are largely in agreement. The overall difference is confirmed, between the relatively lower survival rates for Dutch, English, and French, as opposed to the considerably higher survival rates for German, Icelandic and Irish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
